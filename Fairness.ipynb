{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3F379DMrGE02E3QfsKA7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arturrur/mc853/blob/main/Fairness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook para equidade - Entrega 03"
      ],
      "metadata": {
        "id": "5OswHPLc6bx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import (StratifiedKFold,\n",
        "                                     GridSearchCV)\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import (balanced_accuracy_score,\n",
        "                             make_scorer,\n",
        "                             roc_auc_score,\n",
        "                             recall_score,\n",
        "                             precision_score)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.impute import KNNImputer"
      ],
      "metadata": {
        "id": "RnBnVws97yGL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of kfolds for grid search\n",
        "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)\n",
        "\n",
        "# Set preprocessing: StandardScaler for feature standardization\n",
        "preprocessing = StandardScaler()\n",
        "\n",
        "# Choice of the best hyperparameters through balanced accuracy metric\n",
        "perf = balanced_accuracy_score\n",
        "\n",
        "# Initialize KNNImputer with the specified number of neighbors\n",
        "imputer = KNNImputer(n_neighbors=3)"
      ],
      "metadata": {
        "id": "JwXyCWkt_JPI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_sample(X, y):\n",
        "    '''\n",
        "    Receives a set of features and target feature separately.\n",
        "    Returns balanced data, with the same number of samples in both classes.\n",
        "    If the minority class is less than 5%, applies oversampling and undersampling.\n",
        "    Otherwise, applies only undersampling.\n",
        "    Parameters:\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            The feature matrix.\n",
        "        y : array-like, shape (n_samples,)\n",
        "            The target variable.\n",
        "\n",
        "    Returns:\n",
        "        X_resampled : array-like, shape (n_samples_resampled, n_features)\n",
        "            The resampled feature matrix.\n",
        "        y_resampled : array-like, shape (n_samples_resampled,)\n",
        "            The resampled target variable.\n",
        "    '''\n",
        "\n",
        "    # Define sampling strategies\n",
        "    undersample = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n",
        "    oversample = RandomOverSampler(sampling_strategy=0.2, random_state=1)\n",
        "\n",
        "    # Identify the minority class\n",
        "    count_1 = (y == 1).sum()\n",
        "    count_0 = (y == 0).sum()\n",
        "    count_min = min(count_0, count_1)\n",
        "    count_max = max(count_0, count_1)\n",
        "\n",
        "\n",
        "    # Calculate the percentage of the minority class compared to the total number of instances\n",
        "    ratio = (count_min / count_max)\n",
        "\n",
        "    # If the minority class is more than 60% of the majority class, do not apply any resampling technique\n",
        "    if ratio > 0.6:\n",
        "        X_resampled, y_resampled = X, y\n",
        "\n",
        "    # Check if the percentage of class 1 is at least 5% of the total number of instances\n",
        "    # If it is less than 5%, apply both over and under sampling\n",
        "    else:\n",
        "        if ratio <= 0.2:\n",
        "            X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
        "            X_resampled, y_resampled = undersample.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "        # Otherwise, apply only undersampling\n",
        "        else:\n",
        "            X_resampled, y_resampled = undersample.fit_resample(X, y)\n",
        "\n",
        "    return X_resampled, y_resampled"
      ],
      "metadata": {
        "id": "MaPBQXWgB1_u"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fairness(data, data_test, remove_sensitive=False):\n",
        "  # This function will:\n",
        "  # 1 Remove sensitive atribute's column (optional)\n",
        "  # 2 Resample and normalize data\n",
        "  # 3 Impute missing data\n",
        "  # 4 Train the LogisticRegression model\n",
        "  # 5 Print the True positive rate\n",
        "\n",
        "  # Remove sensitive attribute\n",
        "  senstive_col = data_test['Sexo']\n",
        "  if remove_sensitive:\n",
        "    data = data.drop(columns=['Sexo', 'Gestante'])\n",
        "    data_test = data_test.drop(columns=['Sexo', 'Gestante'])\n",
        "\n",
        "  # Identify target column\n",
        "  target_feature = data.columns[-1]\n",
        "\n",
        "  # Separate features (X) and target (y) for training data\n",
        "  X = data.drop(columns=[target_feature])\n",
        "  y = data[target_feature]\n",
        "\n",
        "  # Separate features (X) and target (y) for test data\n",
        "  X_test = data_test.drop(columns=[target_feature])\n",
        "  y_test = data_test[target_feature]\n",
        "\n",
        "  # Resample training data\n",
        "  X_train, y_train = data_sample(X, y)\n",
        "\n",
        "  # Impute missing data\n",
        "  X_train = imputer.fit_transform(X_train)\n",
        "  X_test = imputer.transform(X_test)\n",
        "\n",
        "  # Normalize data\n",
        "  X_train = preprocessing.fit_transform(X_train)\n",
        "  X_test = preprocessing.transform(X_test)\n",
        "\n",
        "  best = GridSearchCV(LogisticRegression(max_iter=1000), {'class_weight': ('balanced', {0:1, 1:2}, {0:1, 1:3})}, cv=gskf, scoring=(make_scorer(perf)))\n",
        "  best.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = best.predict(X_test)\n",
        "\n",
        "  # Calculating perfomance metrics\n",
        "  recallscore = recall_score(y_test, y_pred, labels=[0, 1], average=None)\n",
        "  sen = recallscore[1]\n",
        "  spe = recallscore[0]\n",
        "\n",
        "  # Calculate precision for each class\n",
        "  prec_score = precision_score(y_test, y_pred, labels=[0, 1], average=None)\n",
        "  prec_n = prec_score[0]\n",
        "  prec_p = prec_score[1]\n",
        "\n",
        "  # Calculate the area under the ROC curve\n",
        "  aucscore = roc_auc_score(y_test, (best.predict_proba((X_test)))[:, 1])\n",
        "  auc = aucscore\n",
        "\n",
        "\n",
        "\n",
        "  # Calculating TPR for each sex\n",
        "  TruePosFem = 0\n",
        "  FalseNegFem = 0\n",
        "  TruePosMale = 0\n",
        "  FalseNegMale = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if senstive_col[i] == 1:\n",
        "      if y_test[i] == 1:\n",
        "        if y_pred[i] == 1:\n",
        "          TruePosFem += 1\n",
        "        else:\n",
        "          FalseNegFem += 1\n",
        "    else:\n",
        "      if y_test[i] == 1:\n",
        "        if y_pred[i] == 1:\n",
        "          TruePosMale += 1\n",
        "        else:\n",
        "          FalseNegMale += 1\n",
        "\n",
        "  print(\"Metrics without sex column\") if remove_sensitive else print(\"Metrics with sex column\")\n",
        "\n",
        "  print(f\"- Recall 1:        {sen:.4f}\")\n",
        "  print(f\"- Recall 0:        {spe:.4f}\")\n",
        "  print(f\"- Precisão 1:      {prec_p:.4f}\")\n",
        "  print(f\"- Precisão 0:      {prec_n:.4f}\")\n",
        "  print(f\"- AUC:             {auc:.4f}\")\n",
        "  print(f\"- Female TPR:      {TruePosFem / (TruePosFem + FalseNegFem)}\")\n",
        "  print(f\"- Male TPR:        {TruePosMale/ (TruePosMale + FalseNegMale)}\")\n"
      ],
      "metadata": {
        "id": "K3aeNzJY8It1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.read_csv('https://raw.githubusercontent.com/arturrur/mc853/refs/heads/main/data/training/treino.csv')\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/arturrur/mc853/refs/heads/main/data/test/teste.csv')\n"
      ],
      "metadata": {
        "id": "mCO5cYUm6lLI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fairness(train_df, test_df)\n",
        "model_fairness(train_df, test_df, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qLYme5iD4LB",
        "outputId": "aefde060-40bf-490f-aa04-c7b55ebecd18"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics with sex column\n",
            "- Recall 1:        0.7297\n",
            "- Recall 0:        0.7922\n",
            "- Precisão 1:      0.2864\n",
            "- Precisão 0:      0.9625\n",
            "- AUC:             0.8526\n",
            "- Female TPR:      0.6530612244897959\n",
            "- Male TPR:        0.75\n",
            "Metrics without sex column\n",
            "- Recall 1:        0.7269\n",
            "- Recall 0:        0.7932\n",
            "- Precisão 1:      0.2866\n",
            "- Precisão 0:      0.9621\n",
            "- AUC:             0.8532\n",
            "- Female TPR:      0.6802721088435374\n",
            "- Male TPR:        0.7392086330935251\n"
          ]
        }
      ]
    }
  ]
}