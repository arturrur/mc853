{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arturrur/mc853/blob/using-KNN-imputer/fun%C3%A7%C3%B5es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "a28f6cca-9c5e-4228-9248-dc682e75a670",
      "metadata": {
        "id": "a28f6cca-9c5e-4228-9248-dc682e75a670"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import pandas as pd                       # For data manipulation and analysis\n",
        "import numpy as np                        # For numerical computing\n",
        "import time                               # For tracking time\n",
        "import math                               # For mathematical operations\n",
        "import warnings                           # For managing warnings\n",
        "\n",
        "import shap                               # For SHAP (SHapley Additive exPlanations) values\n",
        "\n",
        "import imblearn                           # For dealing with imbalanced datasets\n",
        "from imblearn.over_sampling import RandomOverSampler   # For oversampling\n",
        "from imblearn.under_sampling import RandomUnderSampler # For undersampling\n",
        "\n",
        "\n",
        "import seaborn as sns                     # For statistical data visualization\n",
        "import matplotlib.pyplot as plt           # For creating visualizations\n",
        "import matplotlib.patches as mpatches     # For drawing patches in plots\n",
        "import matplotlib.colors as mcolors       # For defining custom colors in plots\n",
        "import matplotlib.ticker as ticker        # For formatting tick marks on plots\n",
        "from matplotlib.ticker import FuncFormatter         # For custom tick formatting\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler      # For feature scaling\n",
        "from sklearn.model_selection import (StratifiedKFold,\n",
        "                                     GridSearchCV) # For splitting data into train and test sets\n",
        "\n",
        "from sklearn.metrics import (roc_auc_score,           # For evaluating model performance\n",
        "                             recall_score,\n",
        "                             make_scorer,\n",
        "                             balanced_accuracy_score,\n",
        "                             confusion_matrix,\n",
        "                             f1_score)\n",
        "\n",
        "from sklearn.svm import SVC                           # For Support Vector Classifier\n",
        "from sklearn.linear_model import LogisticRegression   # For Logistic Regression Classifier\n",
        "from sklearn.ensemble import (RandomForestClassifier, # For ensemble classifiers\n",
        "                              GradientBoostingClassifier,\n",
        "                              BaggingClassifier)\n",
        "from sklearn.neighbors import KNeighborsClassifier # For KNN\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier      # For Multi-layer Perceptron Classifier\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "import re\n",
        "from sklearn.calibration import CalibratedClassifierCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "67ebf0c6-b108-4e25-9a3a-2da7f2717f6a",
      "metadata": {
        "id": "67ebf0c6-b108-4e25-9a3a-2da7f2717f6a"
      },
      "outputs": [],
      "source": [
        "# Set the number of folds for cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
        "\n",
        "# Set the number of kfolds for grid search\n",
        "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)\n",
        "\n",
        "# Choice of the best hyperparameters through balanced accuracy metric\n",
        "perf = balanced_accuracy_score\n",
        "\n",
        "# Set preprocessing: StandardScaler for feature standardization\n",
        "preprocessing = StandardScaler()\n",
        "\n",
        "# Initialize KNNImputer with the specified number of neighbors\n",
        "imputer = KNNImputer(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "ff5a01e1-3ee8-4e70-b1ed-71d1795095ae",
      "metadata": {
        "id": "ff5a01e1-3ee8-4e70-b1ed-71d1795095ae"
      },
      "outputs": [],
      "source": [
        "# Define a dictionary containing various classification algorithms and their parameters used in grid search\n",
        "\n",
        "algorithms = {\n",
        "    'knn': (KNeighborsClassifier(), {\"n_neighbors\": [1, 5, 10], \"weights\": ('uniform', 'distance')}),\n",
        "    # K-Nearest Neighbors Classifier\n",
        "\n",
        "    'random_forest': (RandomForestClassifier(random_state=0), {'n_estimators': [10, 100, 200], 'max_depth': [10, 50], 'min_samples_split': [2, 10, 30]}),\n",
        "    # Random Forest Classifier\n",
        "\n",
        "    'logistic_regression': (LogisticRegression(), {'class_weight': ('balanced', {0:1, 1:2}, {0:1, 1:3})}),\n",
        "    # Logistic Regression Classifier\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zA7am_xbEmFE"
      },
      "id": "zA7am_xbEmFE"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a1a580b6-211d-4a4d-85a0-e62afb275421",
      "metadata": {
        "id": "a1a580b6-211d-4a4d-85a0-e62afb275421"
      },
      "outputs": [],
      "source": [
        "def data_sample(X, y):\n",
        "    '''\n",
        "    Receives a set of features and target feature separately.\n",
        "    Returns balanced data, with the same number of samples in both classes.\n",
        "    If the minority class is less than 5%, applies oversampling and undersampling.\n",
        "    Otherwise, applies only undersampling.\n",
        "    Parameters:\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            The feature matrix.\n",
        "        y : array-like, shape (n_samples,)\n",
        "            The target variable.\n",
        "\n",
        "    Returns:\n",
        "        X_resampled : array-like, shape (n_samples_resampled, n_features)\n",
        "            The resampled feature matrix.\n",
        "        y_resampled : array-like, shape (n_samples_resampled,)\n",
        "            The resampled target variable.\n",
        "    '''\n",
        "\n",
        "    # Define sampling strategies\n",
        "    undersample = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n",
        "    oversample = RandomOverSampler(sampling_strategy=0.2, random_state=1)\n",
        "\n",
        "    # Identify the minority class\n",
        "    count_1 = (y == 1).sum()\n",
        "    count_0 = (y == 0).sum()\n",
        "    count_min = min(count_0, count_1)\n",
        "    count_max = max(count_0, count_1)\n",
        "\n",
        "\n",
        "    # Calculate the percentage of the minority class compared to the total number of instances\n",
        "    ratio = (count_min / count_max)\n",
        "\n",
        "    # If the minority class is more than 60% of the majority class, do not apply any resampling technique\n",
        "    if ratio > 0.6:\n",
        "        X_resampled, y_resampled = X, y\n",
        "\n",
        "    # Check if the percentage of class 1 is at least 5% of the total number of instances\n",
        "    # If it is less than 5%, apply both over and under sampling\n",
        "    else:\n",
        "        if ratio <= 0.2:\n",
        "            X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
        "            X_resampled, y_resampled = undersample.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "        # Otherwise, apply only undersampling\n",
        "        else:\n",
        "            X_resampled, y_resampled = undersample.fit_resample(X, y)\n",
        "\n",
        "    return X_resampled, y_resampled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7192dcb9-be8b-41ed-ac10-9302fad1a7a6",
      "metadata": {
        "id": "7192dcb9-be8b-41ed-ac10-9302fad1a7a6"
      },
      "outputs": [],
      "source": [
        "def impute_missing(data, n_neighbors=3):\n",
        "    \"\"\"\n",
        "    Impute missing values using the K-nearest neighbors algorithm.\n",
        "\n",
        "    Parameters:\n",
        "        data (pd.DataFrame): Input DataFrame with missing values.\n",
        "        n_neighbors (int, optional): Number of neighbors to use for imputation. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with missing values imputed using KNN.\n",
        "    \"\"\"\n",
        "    # Initialize KNNImputer with the specified number of neighbors\n",
        "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "\n",
        "    # Perform imputation\n",
        "    imputed_data = imputer.fit_transform(data)\n",
        "\n",
        "    # Convert the imputed array back to a DataFrame\n",
        "    imputed_df = pd.DataFrame(imputed_data, columns=data.columns, index=data.index)\n",
        "\n",
        "    return imputed_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bfe8f23f-9dd9-4e7f-9844-7dd573137f53",
      "metadata": {
        "id": "bfe8f23f-9dd9-4e7f-9844-7dd573137f53"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "def evaluate_cv(data):\n",
        "    '''\n",
        "    Receives data to be evaluated and returns the average performance inside cross-validation, using 3 metrics.\n",
        "    Applies over-under sampling to get balanced datasets and standardizes features.\n",
        "\n",
        "    Parameters:\n",
        "    data : DataFrame\n",
        "        The dataset containing features and the target variable.\n",
        "\n",
        "    Returns:\n",
        "    df : DataFrame\n",
        "        A DataFrame containing the mean and standard deviation of each algorithm's performance across 5-fold cross-validation.\n",
        "        The performance metrics include AUC (mean and standard deviation), sensitivity (mean and standard deviation),\n",
        "        specificity (mean and standard deviation), prec_n (mean and standard deviation), and prec_p (mean and standard deviation).\n",
        "    '''\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Identify the target column\n",
        "    target_feature = data.columns[-1]\n",
        "\n",
        "    # Separate features (X) and target (y)\n",
        "    X = data.drop(columns=[target_feature])\n",
        "    y = data[target_feature]\n",
        "\n",
        "    # Initialize dictionaries to store metrics for each algorithm\n",
        "    sen = {}\n",
        "    spe = {}\n",
        "    auc = {}\n",
        "    prec_n = {}  # Negative precision\n",
        "    prec_p = {}  # Positive precision\n",
        "\n",
        "    for algorithm in algorithms.keys():\n",
        "        sen[algorithm] = []\n",
        "        spe[algorithm] = []\n",
        "        auc[algorithm] = []\n",
        "        prec_n[algorithm] = []\n",
        "        prec_p[algorithm] = []\n",
        "\n",
        "    for algorithm, (clf, parameters) in algorithms.items():\n",
        "      best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
        "\n",
        "      # Iterate through each round of the cross-validation\n",
        "\n",
        "      for train, test in kf.split(X, y):\n",
        "        # Allocate train and test data\n",
        "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
        "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
        "\n",
        "        # # Apply over-under sampling\n",
        "        # X_train, y_train = data_sample(X_train, y_train)\n",
        "\n",
        "        # X_train = imputer.fit_transform(X_train)\n",
        "        # X_test = imputer.transform(X_test)\n",
        "\n",
        "        # Standardize features\n",
        "        X_train = preprocessing.fit_transform(X_train)\n",
        "        X_test = preprocessing.transform(X_test)\n",
        "\n",
        "        # Find best hyperparameters\n",
        "        best.fit((X_train), y_train)\n",
        "\n",
        "        # Make predictions for the test data\n",
        "        y_pred = best.predict(X_test)\n",
        "\n",
        "        # Calculate sensitivity and specificity\n",
        "        recallscore = recall_score(y_test, y_pred, labels=[0, 1], average=None)\n",
        "        sen[algorithm].append(recallscore[1])\n",
        "        spe[algorithm].append(recallscore[0])\n",
        "\n",
        "        # Calculate precision for each class\n",
        "        prec_score = precision_score(y_test, y_pred, labels=[0, 1], average=None)\n",
        "        prec_n[algorithm].append(prec_score[0])\n",
        "        prec_p[algorithm].append(prec_score[1])\n",
        "\n",
        "        # Calculate the area under the ROC curve\n",
        "        aucscore = roc_auc_score(y_test, (best.predict_proba((X_test)))[:, 1])\n",
        "        auc[algorithm].append(aucscore)\n",
        "\n",
        "    # Create a DataFrame with the mean and standard deviation of each algorithm's performance across 5 folds\n",
        "    df = pd.DataFrame(columns=list(algorithms.keys()))\n",
        "\n",
        "    df.loc['auc (mean)'] = [np.mean(auc['knn']), np.mean(auc['random_forest']), np.mean(auc['logistic_regression'])]\n",
        "    df.loc['auc (stdev)'] = [np.std(auc['knn']), np.std(auc['random_forest']), np.std(auc['logistic_regression'])]\n",
        "\n",
        "    df.loc['rcl_1 (mean)'] = [np.mean(sen['knn']), np.mean(sen['random_forest']), np.mean(sen['logistic_regression'])]\n",
        "    df.loc['rcl_1 (stdev)'] = [np.std(sen['knn']), np.std(sen['random_forest']), np.std(sen['logistic_regression'])]\n",
        "\n",
        "    df.loc['rcl_0 (mean)'] = [np.mean(spe['knn']), np.mean(spe['random_forest']), np.mean(spe['logistic_regression'])]\n",
        "    df.loc['rcl_0 (stdev)'] = [np.std(spe['knn']), np.std(spe['random_forest']), np.std(spe['logistic_regression'])]\n",
        "\n",
        "    df.loc['prc_1 (mean)'] = [np.mean(prec_p['knn']), np.mean(prec_p['random_forest']), np.mean(prec_p['logistic_regression'])]\n",
        "    df.loc['prc_1 (stdev)'] = [np.std(prec_p['knn']), np.std(prec_p['random_forest']), np.std(prec_p['logistic_regression'])]\n",
        "\n",
        "    df.loc['prc_0 (mean)'] = [np.mean(prec_n['knn']), np.mean(prec_n['random_forest']), np.mean(prec_n['logistic_regression'])]\n",
        "    df.loc['prc_0 (stdev)'] = [np.std(prec_n['knn']), np.std(prec_n['random_forest']), np.std(prec_n['logistic_regression'])]\n",
        "\n",
        "\n",
        "    # Set caption for DataFrame\n",
        "    df = df.style.set_caption('Average performance and standard deviation among 5-fold cross-validation')\n",
        "\n",
        "    # Record the end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time taken\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    # Display the DataFrame\n",
        "    display(df)\n",
        "\n",
        "    # Print the total time taken to run cross-validation\n",
        "    print(f\"Total time taken to run cross-validation: {total_time:.2f} seconds\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "e691d3fe-206c-4b5b-ad01-c57388737cf3",
      "metadata": {
        "id": "e691d3fe-206c-4b5b-ad01-c57388737cf3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "def evaluate_external(data, data_test):\n",
        "    '''\n",
        "    Receives data and data_test to be evaluated and returns the average performance, using 3 metrics.\n",
        "    Applies over-under sampling to get balanced datasets and standardizes features.\n",
        "\n",
        "    Parameters:\n",
        "    data : DataFrame\n",
        "        The training dataset containing features and the target variable.\n",
        "    data_test : DataFrame\n",
        "        The test dataset containing features and the target variable.\n",
        "\n",
        "    Returns:\n",
        "    df : DataFrame\n",
        "        A DataFrame containing the mean performance of each algorithm across external validation.\n",
        "        The performance metrics include AUC (mean), sensitivity (mean), specificity (mean), prec_n (mean), and prec_p (mean).\n",
        "    '''\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Identify the target column\n",
        "    target_feature = data.columns[-1]\n",
        "\n",
        "    # Separate features (X) and target (y) for training data\n",
        "    X = data.drop(columns=[target_feature])\n",
        "    y = data[target_feature]\n",
        "\n",
        "    # Separate features (X) and target (y) for test data\n",
        "    X_test = data_test.drop(columns=[target_feature])\n",
        "    y_test = data_test[target_feature]\n",
        "\n",
        "    # Initialize dictionaries to store metrics for each algorithm\n",
        "    sen = {}\n",
        "    spe = {}\n",
        "    auc = {}\n",
        "    prec_n = {}  # Negative precision\n",
        "    prec_p = {}  # Positive precision\n",
        "\n",
        "    for algorithm in algorithms.keys():\n",
        "        sen[algorithm] = []\n",
        "        spe[algorithm] = []\n",
        "        auc[algorithm] = []\n",
        "        prec_n[algorithm] = []\n",
        "        prec_p[algorithm] = []\n",
        "\n",
        "    # Apply over-under sampling to training data\n",
        "    #X_train, y_train = data_sample(X, y)\n",
        "\n",
        "\n",
        "    #X_train = imputer.fit_transform(X_train)\n",
        "    #X_test = imputer.transform(X_test)\n",
        "    X_train = X\n",
        "    y_train = y\n",
        "\n",
        "    # Apply preprocessing to both training and test data\n",
        "    X_train = preprocessing.fit_transform(X_train)\n",
        "    X_test = preprocessing.transform(X_test)\n",
        "\n",
        "    # For each algorithm\n",
        "    for algorithm, (clf, parameters) in algorithms.items():\n",
        "        # Train model\n",
        "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
        "        best.fit((X_train), y_train)\n",
        "\n",
        "        # Make predictions for the test data\n",
        "        y_pred = best.predict(X_test)\n",
        "\n",
        "        # Calculate sensitivity and specificity\n",
        "        recallscore = recall_score(y_test, y_pred, labels=[0, 1], average=None)\n",
        "        sen[algorithm].append(recallscore[1])\n",
        "        spe[algorithm].append(recallscore[0])\n",
        "\n",
        "        # Calculate precision for each class\n",
        "        prec_score = precision_score(y_test, y_pred, labels=[0, 1], average=None)\n",
        "        prec_n[algorithm].append(prec_score[0])\n",
        "        prec_p[algorithm].append(prec_score[1])\n",
        "\n",
        "        # Calculate the area under the ROC curve\n",
        "        aucscore = roc_auc_score(y_test, (best.predict_proba((X_test)))[:, 1])\n",
        "        auc[algorithm].append(aucscore)\n",
        "\n",
        "        print(f\"confusion matrix for algorithm: {algorithm}\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Create a DataFrame with the mean performance of each algorithm across the external validation\n",
        "    df = pd.DataFrame(columns=list(algorithms.keys()))\n",
        "\n",
        "    df.loc['auc (mean)'] = [np.mean(auc['knn']), np.mean(auc['random_forest']), np.mean(auc['logistic_regression'])]\n",
        "\n",
        "    df.loc['rcl_1 (mean)'] = [np.mean(sen['knn']), np.mean(sen['random_forest']), np.mean(sen['logistic_regression'])]\n",
        "\n",
        "    df.loc['rcl_0 (mean)'] = [np.mean(spe['knn']), np.mean(spe['random_forest']), np.mean(spe['logistic_regression'])]\n",
        "\n",
        "    df.loc['prc_1 (mean)'] = [np.mean(prec_p['knn']), np.mean(prec_p['random_forest']), np.mean(prec_p['logistic_regression'])]\n",
        "\n",
        "    df.loc['prc_0 (mean)'] = [np.mean(prec_n['knn']), np.mean(prec_n['random_forest']), np.mean(prec_n['logistic_regression'])]\n",
        "\n",
        "    # Set caption for DataFrame\n",
        "    df = df.style.set_caption('Performance for external validation')\n",
        "\n",
        "    # Record the end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time taken\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    # Display the DataFrame\n",
        "    display(df)\n",
        "\n",
        "    # Print the total time taken to run external-validation\n",
        "    print(f\"Total time taken to run external-validation: {total_time:.2f} seconds\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf112f5",
      "metadata": {
        "id": "dcf112f5"
      },
      "source": [
        "Cross-validation usando dados treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "19fe7911",
      "metadata": {
        "id": "19fe7911"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/arturrur/mc853/refs/heads/using-KNN-imputer/data/training/treino.csv')\n",
        "\n",
        "# impute NaN values in Escolaridade column\n",
        "df_full = impute_missing(df)\n",
        "\n",
        "# resample data so death and survival are 50-50\n",
        "target_feature = df.columns[-1]\n",
        "x_balanced, y_balanced = data_sample(df_full.drop(columns=[target_feature]), df_full[target_feature])\n",
        "df_balanced = pd.concat([x_balanced, y_balanced], axis=1)\n",
        "\n",
        "# evaluates\n",
        "evaluate_cv(df_balanced);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validação externa do modelo"
      ],
      "metadata": {
        "id": "_02wiVM02Gfl"
      },
      "id": "_02wiVM02Gfl"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "c7b6121c-30a7-4308-a612-031828306cc5",
      "metadata": {
        "id": "c7b6121c-30a7-4308-a612-031828306cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "5a4630b6-afe9-4d2d-fb5b-d93decf2d161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix for algorithm: knn\n",
            "[[1548  547]\n",
            " [ 114  201]]\n",
            "confusion matrix for algorithm: random_forest\n",
            "[[1625  470]\n",
            " [  99  216]]\n",
            "confusion matrix for algorithm: logistic_regression\n",
            "[[1201  894]\n",
            " [  36  279]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e8d75c56910>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_61a53\" class=\"dataframe\">\n",
              "  <caption>Performance for external validation</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_61a53_level0_col0\" class=\"col_heading level0 col0\" >knn</th>\n",
              "      <th id=\"T_61a53_level0_col1\" class=\"col_heading level0 col1\" >random_forest</th>\n",
              "      <th id=\"T_61a53_level0_col2\" class=\"col_heading level0 col2\" >logistic_regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_61a53_level0_row0\" class=\"row_heading level0 row0\" >auc (mean)</th>\n",
              "      <td id=\"T_61a53_row0_col0\" class=\"data row0 col0\" >0.755481</td>\n",
              "      <td id=\"T_61a53_row0_col1\" class=\"data row0 col1\" >0.801783</td>\n",
              "      <td id=\"T_61a53_row0_col2\" class=\"data row0 col2\" >0.813818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61a53_level0_row1\" class=\"row_heading level0 row1\" >rcl_1 (mean)</th>\n",
              "      <td id=\"T_61a53_row1_col0\" class=\"data row1 col0\" >0.638095</td>\n",
              "      <td id=\"T_61a53_row1_col1\" class=\"data row1 col1\" >0.685714</td>\n",
              "      <td id=\"T_61a53_row1_col2\" class=\"data row1 col2\" >0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61a53_level0_row2\" class=\"row_heading level0 row2\" >rcl_0 (mean)</th>\n",
              "      <td id=\"T_61a53_row2_col0\" class=\"data row2 col0\" >0.738902</td>\n",
              "      <td id=\"T_61a53_row2_col1\" class=\"data row2 col1\" >0.775656</td>\n",
              "      <td id=\"T_61a53_row2_col2\" class=\"data row2 col2\" >0.573270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61a53_level0_row3\" class=\"row_heading level0 row3\" >prc_1 (mean)</th>\n",
              "      <td id=\"T_61a53_row3_col0\" class=\"data row3 col0\" >0.268717</td>\n",
              "      <td id=\"T_61a53_row3_col1\" class=\"data row3 col1\" >0.314869</td>\n",
              "      <td id=\"T_61a53_row3_col2\" class=\"data row3 col2\" >0.237852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61a53_level0_row4\" class=\"row_heading level0 row4\" >prc_0 (mean)</th>\n",
              "      <td id=\"T_61a53_row4_col0\" class=\"data row4 col0\" >0.931408</td>\n",
              "      <td id=\"T_61a53_row4_col1\" class=\"data row4 col1\" >0.942575</td>\n",
              "      <td id=\"T_61a53_row4_col2\" class=\"data row4 col2\" >0.970897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time taken to run external-validation: 26.14 seconds\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv('https://raw.githubusercontent.com/arturrur/mc853/refs/heads/using-KNN-imputer/data/test/teste.csv')\n",
        "\n",
        "# impute missing values for df_test\n",
        "df_full_test = impute_missing(df_test)\n",
        "\n",
        "# evaluates\n",
        "evaluate_external(df_balanced, df_full_test);"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}